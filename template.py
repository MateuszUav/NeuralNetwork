# -*- coding: utf-8 -*-
"""template.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pUxl7Tf8tFpUUM8geVgQe9d6MqgvpvFp
"""

# =========================================================
# --- Opcjonalnie : montowanie Google Drive ---
# =========================================================
from google.colab import drive
import os

# Montowanie dysku Google
drive.mount('/content/drive')

# Ścieżka do folderu roboczego na Drive
base_export_dir = '/content/drive/MyDrive/colab_cifar10_exports'
os.makedirs(base_export_dir, exist_ok=True)

print(f"[OK] Google Drive podłączony. Pliki będą zapisywane w:\n{base_export_dir}")

# =========================================================
# --- 0. Import bibliotek ---
# =========================================================
import numpy as np
import matplotlib.pyplot as plt
import datetime

from keras.datasets import cifar10
from keras.models import Sequential
from keras.layers import (
    Input,
    Conv2D,
    BatchNormalization,
    Activation,
    MaxPooling2D,
    GlobalAveragePooling2D,
    Flatten,
    Dense,
    Dropout
)
from keras.optimizers import Adam
from keras.utils import to_categorical
from keras.callbacks import EarlyStopping, ReduceLROnPlateau

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# =========================================================
# --- 1. Importowanie danych CIFAR10 ---
# =========================================================
# Wczytanie zbioru danych CIFAR10
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# Wyświetlenie przykładowego obrazu (opcjonalne)
print("Etykieta przykładowego obrazu:", y_train[0])
plt.imshow(x_train[0])
plt.axis('off')
plt.show()

# =========================================================
# --- 2. Wstępne przetwarzanie danych ---
# =========================================================
# Normalizacja do zakresu [0,1] i dodanie kanału (H,W,1)
x_train = x_train.astype('float32') / 255.0
x_test  = x_test.astype('float32') / 255.0

# One-hot encoding etykiet
num_classes = 10
y_train_cat = to_categorical(y_train, num_classes)
y_test_cat  = to_categorical(y_test, num_classes)

# lista nazw klas CIFAR-10 (użyteczna w wyświetleniach)
class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']

# =========================================================
# --- 3. Definicja modelu sieci neuronowej ---
# =========================================================
input_shape = (32, 32, 3)  # CIFAR-10 to 32x32 RGB

model = Sequential([
    Input(shape=input_shape),
    Conv2D(32, (3,3), activation='relu'),
    MaxPooling2D((2,2)),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D((2,2)),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(num_classes, activation='softmax')
])

# =========================================================
# --- 4. Kompilacja modelu ---
# =========================================================
# Optymalizator Adam, funkcja straty categorical_crossentropy, metryka accuracy
model.compile(
    optimizer=Adam(learning_rate=1e-2),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Wyświetlenie podsumowania modelu
model.summary()

# =========================================================
# --- 5. Trenowanie modelu ---
# =========================================================
es = EarlyStopping(
    monitor='val_accuracy',   # metryka, którą obserwujemy (np. val_loss, val_accuracy)
    patience=3,               # liczba epok bez poprawy, po których zatrzymujemy trening
    min_delta=1e-3,           # minimalna wymagana zmiana, by uznać, że jest „poprawa”
    mode='max'              # 'min' jeśli monitorujemy straty, 'max' jeśli dokładność
)
rlp = ReduceLROnPlateau(
    monitor='val_accuracy',   # metryka do obserwacji
    factor=0.5,           # ile razy zmniejszyć LR (tu: o połowę)
    patience=3,           # liczba epok bez poprawy przed zmniejszeniem LR, rlp.patience < es.patience
    min_delta=1e-3,       # próg czułości jak wyżej
    min_lr=1e-4,          # dolna granica learning rate
    mode='max',           # 'min' dla strat, 'max' dla dokładności
)

history = model.fit(
    x_train,
    y_train_cat,
    batch_size=64,
    epochs=10,
    validation_data=(x_test, y_test_cat),
    callbacks=[es, rlp],
    verbose=1
)

# Data skończenia treningu - timestamp - znacznik do zapisywania plików
ts = datetime.datetime.now().strftime("_%Y%m%d_%H%M")

# =========================================================
# --- 6. Ewaluacja modelu ---
# =========================================================
loss, accuracy = model.evaluate(x_test, y_test_cat, verbose=0)
print('Dokładność na zbiorze testowym:', f"{accuracy:.2f}")
print('Strata na zbiorze testowym:', f"{loss:.2f}")

# =========================================================
# --- 7. Wizualizacja przebiegu treningu (loss) ---
# =========================================================
fig_loss_acc = plt.figure(figsize=(10,4))

plt.subplot(1,2,1)
plt.plot(history.history['loss'], label='loss (train)')
plt.plot(history.history['val_loss'], label='loss (val)')
plt.xlabel('Epoka')
plt.ylabel('categorical_crossentropy')
plt.title(f'Strata na zbiorze testowym to {loss:.2f}')
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history['accuracy'], label='accuracy (train)')
plt.plot(history.history['val_accuracy'], label='accuracy (val)')
plt.xlabel('Epoka')
plt.ylabel('Accuracy')
plt.title(f"Dokładność na zbiorze testowym to {accuracy:.2f}")
plt.legend()
plt.tight_layout()

# Zapis wykresu
loss_acc_path = os.path.join(base_export_dir, f'training_loss_accuracy{ts}.png')
fig_loss_acc.savefig(loss_acc_path)
print("Zapisano wykres loss/accuracy ->", loss_acc_path)

plt.show()

# =========================================================
# --- 8. Wizualizacja błędnych klasyfikacji i macierz pomyłek ---
# =========================================================
# Predykcje (etykiety)
pred_probs = model.predict(x_test)
pred_labels = np.argmax(pred_probs, axis=1)
true_labels = np.argmax(y_test_cat, axis=1)  # lub po prostu y_test

# Indeksy błędnych klasyfikacji
incorrect_indices = np.nonzero(pred_labels != true_labels)[0]

# Wyświetlenie kilku błędnych przykładów
n_show = min(3, len(incorrect_indices))
for i in range(n_show):
    idx = incorrect_indices[i]
    plt.figure(figsize=(3,3))
    plt.imshow(x_test[idx].squeeze(), cmap='gray')
    plt.title(f"Prawidłowo: {class_names[true_labels[idx]]}  -> Predykcja: {class_names[pred_labels[idx]]}")
    plt.axis('off')
    plt.show()

# Confusion matrix
cm = confusion_matrix(true_labels, pred_labels)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
fig_cm, ax = plt.subplots(figsize=(8,8))
disp.plot(ax=ax, cmap='Blues', colorbar=False)
plt.title('Macierz pomyłek')
# Zapis wykresu
loss_acc_path = os.path.join(base_export_dir, f'confusion_matrix{ts}.png')
fig_cm.savefig(loss_acc_path)
print("Zapisano macierz pomyłek ->", loss_acc_path)
plt.show()

# =========================================================
# --- 9. Zapis modelu ---
# =========================================================
model_path = os.path.join(base_export_dir, f"my_model{ts}.keras")
model.save(model_path)
print("Model zapisany jako", model_path)